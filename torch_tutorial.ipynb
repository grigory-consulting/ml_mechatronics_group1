{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f3551681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ceace385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1,2,3]) # tensor is n-dimensional array\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "47a94ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0152, 0.3439, 0.5670],\n",
       "        [0.1282, 0.0977, 0.2425]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(2,3) # random tensor, 2 rows, 3 columns\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "41f62e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros(2,3)\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e7ce47e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor = torch.ones(2,3)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97453bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [2., 3., 4.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb90b80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 22.],\n",
       "        [43., 50.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1.,2], [3,4]])\n",
    "b = torch.tensor([[5.,6], [7,8]])\n",
    "a @ b # torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c9a7668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5., 12.],\n",
       "        [21., 32.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fc8c5828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6a1dc784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9310f702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu, cuda, mps and possibly other frameworks \n",
    "\n",
    "# torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\") # for ordinary cpu\n",
    "device = torch.device(\"cpu\") # for CUDA\n",
    "device = torch.device(\"mps\") # for Apple Silicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e4ef07c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradients \n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True) # mode: propagate the gradients over all computation steps\n",
    "y = x**2 + 3*x +5\n",
    "# 2*x +3 -> 2*2 + 3 = 7\n",
    "y.backward() # compute gradients using backpropagation algorithm\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729bccda",
   "metadata": {},
   "source": [
    "- easy NN, one gradient descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47d58b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7 (before update)\n",
      "Loss: 1.4 (after update)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn # Neural Networks \n",
    "import torch.optim as optim # optimizer framework for gradient methods \n",
    "\n",
    "# 10 inputs, 1 output -> fully connected feed-forward neural network\n",
    "NN = nn.Linear(10,1) # W*x + b, in Tensorflow -> Dense\n",
    "# MLP -> Multi-Layer Perceptron \n",
    "# in Literature/Publications: FC, FFN, FFNN, MLP \n",
    "\n",
    "loss = nn.MSELoss() # mean squared error\n",
    "# loss, cost, criterion, crit \n",
    "optimizer = optim.SGD(NN.parameters(), lr = 1e-2)\n",
    "# lr = learning rate, eta, alpha \n",
    "# NN.parameters() ... weights and biases\n",
    "\n",
    "input_data = torch.rand(10) # random stuff, X \n",
    "output = NN(input_data) # y_pred, predictions, y_hat \n",
    "y = torch.ones(1) # ground truth, target, regr \n",
    "\n",
    "# initial value of the loss function \n",
    "loss_output = loss(y, output) # Difference between reality and expectation \n",
    "print(f\"Loss: {loss_output:.2} (before update)\")\n",
    "\n",
    "# two magical lines\n",
    "loss_output.backward() # compute gradients\n",
    "optimizer.step() # Update the weights and biases \n",
    "\n",
    "output_new = NN(input_data) # here are new weights and biases \n",
    "loss_new = loss(output_new,y) # value of the loss function after the update\n",
    "print(f\"Loss: {loss_new:.2} (after update)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a281870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "61a7dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3046], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output # before Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8aacfb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1997], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfdbfd",
   "metadata": {},
   "source": [
    "# FashionMNIST dataset \n",
    "- modern HelloWorld for NNs (by Zalando)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1f18bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert to tensor\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "33cc8d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109386"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28*128 + 128 + 128*64 + 64 + 64*10+10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "85a9433d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100480"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28*128 + 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0f76b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "\n",
    "class NN(nn.Module): # class \n",
    "\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__() # init from the superclass\n",
    "        self.layer1 = nn.Linear(28*28, 128 ) # input layer \n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.layer2 = nn.Linear(128, 64) # hidden layer\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.layer3 = nn.Linear(64 ,10)         # output layer, 10 number of product categories\n",
    "        self.drop = nn.Dropout(0.3) # 30 % of activations are set to zero\n",
    "        # 0.1 -> 0.2 -> ... -> 0.5 \n",
    "    \n",
    "    # First way to apply BatchNorm (preactivation)\n",
    "    def forward(self,x): # propagate the information through the network\n",
    "        x = x.view(-1, 28*28) # flatten 2D -> 1D \n",
    "        x = torch.relu(self.bn1(self.layer1(x))) # activation using ReLU\n",
    "        x = self.drop(x) \n",
    "        x = torch.relu(self.bn2(self.layer2(x))) \n",
    "        x = self.drop(x) # here dropout is usually placed \n",
    "        x = self.layer3(x) # identity activation -> logit (no need to compute gradients of softmax)\n",
    "        return x \n",
    "    # Second way to apply BatchNorm (postactivation)\n",
    "    def forward(self,x): # propagate the information through the network\n",
    "        x = x.view(-1, 28*28) # flatten 2D -> 1D \n",
    "        x = torch.relu(self.layer1(x)) # activation using ReLU\n",
    "        x = self.bn1(x)\n",
    "        x = self.drop(x) \n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.drop(x) # here dropout is usually placed \n",
    "        x = self.layer3(x) # identity activation -> logit (no need to compute gradients of softmax)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "451e5223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/20], Loss: 671.2218017578125\n",
      "Epoch[2/20], Loss: 482.37066650390625\n",
      "Epoch[3/20], Loss: 442.262451171875\n",
      "Epoch[4/20], Loss: 424.709716796875\n",
      "Epoch[5/20], Loss: 401.94439697265625\n",
      "Epoch[6/20], Loss: 392.5033264160156\n",
      "Epoch[7/20], Loss: 383.63427734375\n",
      "Epoch[8/20], Loss: 379.515869140625\n",
      "Epoch[9/20], Loss: 372.1685485839844\n",
      "Epoch[10/20], Loss: 370.48175048828125\n",
      "Epoch[11/20], Loss: 369.0382385253906\n",
      "Epoch[12/20], Loss: 368.524658203125\n",
      "Epoch[13/20], Loss: 364.98260498046875\n",
      "Epoch[14/20], Loss: 354.603759765625\n",
      "Epoch[15/20], Loss: 354.80328369140625\n",
      "Epoch[16/20], Loss: 356.435302734375\n",
      "Epoch[17/20], Loss: 353.4370422363281\n",
      "Epoch[18/20], Loss: 347.3802795410156\n",
      "Epoch[19/20], Loss: 353.01104736328125\n",
      "Epoch[20/20], Loss: 347.5052185058594\n"
     ]
    }
   ],
   "source": [
    "# Now training\n",
    "\n",
    "model = NN()\n",
    "lr = 1e-2 # learning rate\n",
    "loss = nn.CrossEntropyLoss() # CE because multi-class problem\n",
    "optimizer = optim.SGD(model.parameters(), lr = lr )\n",
    "\n",
    "n_epochs = 20 \n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # train mode\n",
    "    running_loss = 0.0 # loss per epoch\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad() # reset the gradients\n",
    "        # forward \n",
    "        outputs = model(images) # calculate outputs\n",
    "        curr_loss = loss(outputs,labels)\n",
    "        running_loss += curr_loss\n",
    "        # backward\n",
    "        curr_loss.backward() # gradients\n",
    "        optimizer.step()     # update weights and biases\n",
    "    print(f\"Epoch[{epoch + 1}/{n_epochs}], Loss: {running_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d0364fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97f5cc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d85d1fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.57%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation \n",
    "\n",
    "model.eval() # setting the model to evaluation mode (implementation optimization)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # we are not interested in gradient anymore \n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        predicted = torch.max(outputs.data, 1)[-1] \n",
    "        total += labels.size(0) \n",
    "        correct += (predicted==labels).sum().item()\n",
    "\n",
    "accuracy = correct/total\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
