{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f383dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"I am a boy.\"\n",
    "target = \"Ich bin ein Junge.\"\n",
    "\n",
    "# ----------\n",
    "# Encoder[\"I am a boy.\"] -> h \n",
    "# Next Token Prediction \n",
    "# 1. step Decoder [h, <bos>] -> \"ich\"\n",
    "# 2. step Decoder [h, (<bos>, \"ich\")] -> \"bin\" \n",
    "# 3. step Decoder [h, (<bos>, \"ich\", \"bin\")] -> \"ein\"\n",
    "# 4. step Decoder [h, (<bos>, \"ich\", \"bin\", \"ein\")] -> \"Junge\"\n",
    "# 5. step Decoder [h, (<bos>, \"ich\", \"bin\", \"ein\", \"Junge\")] -> \"<eos>\"\n",
    "\n",
    "# X = (h, (<bos>, \"ich\", \"bin\", \"ein\", \"Junge\")) -> input for Decoder\n",
    "# y = ( \"ich\", \"bin\", \"ein\", \"Junge\", <eos>) -> target/labels for Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0f081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "path = \"./deu.txt\"\n",
    "\n",
    "lines = open(path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "lines = lines[:20000]\n",
    "\n",
    "pairs = [ln.split(\"\\t\")[:2] for ln in lines] \n",
    "src_texts, tgt_texts = zip(*pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2609cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, UNK, BOS, EOS = 0, 1, 2, 3 # special tokens\n",
    "# PAD = Padding, UNK = Unknown,\n",
    "# BOS, EOS \n",
    "\n",
    "VOCAB_SIZE = 20004 \n",
    "\n",
    "def tokenize(s): return re.findall(r\"\\b\\w+\\b\", s.lower())\n",
    "def build_vocab(texts, max_tokens=VOCAB_SIZE):\n",
    "    from collections import Counter\n",
    "    freq = Counter(tok for t in texts for tok in tokenize(t))\n",
    "    itos = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"] + [w for w,_ in freq.most_common(max_tokens-4)]\n",
    "    return {w:i for i,w in enumerate(itos)}, itos\n",
    "src_texts_vocab, src_itos = build_vocab(src_texts)\n",
    "tgt_texts_vocab, tgt_itos = build_vocab(tgt_texts)\n",
    "\n",
    "\n",
    "\n",
    "def vectorize(text, stoi, max_len, add_bos_eos=False):\n",
    "    ids = [stoi.get(tok, UNK) for tok in tokenize(text)]\n",
    "    if add_bos_eos: ids = [BOS] + ids + [EOS]\n",
    "    ids = ids[:max_len]\n",
    "    if len(ids) < max_len: ids += [PAD]*(max_len-len(ids))\n",
    "    return ids\n",
    "\n",
    "#vectorize(src_texts[60], src_texts_vocab, 30)\n",
    "#src_texts[60]\n",
    "\n",
    "\n",
    "max_src, max_tgt = 30, 30 \n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src = torch.tensor([vectorize(t, src_texts_vocab, max_src) for t in src_batch])\n",
    "    tgt = torch.tensor([vectorize(t, tgt_texts_vocab, max_tgt, add_bos_eos=True) for t in tgt_batch])\n",
    "    tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "    return src, tgt_in, tgt_out\n",
    "\n",
    "dataset = list(zip(src_texts, tgt_texts))\n",
    "loader = DataLoader(dataset, batch_size= 64, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfc8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5594"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_texts_vocab) # number of tokens in source\n",
    "len(tgt_texts_vocab) # number of tokens in target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5458f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': 0, 'for': 1, 'is': 2, 'sample': 3, 'sentence': 4, 'this': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"this is sample sentence for embedding\"\n",
    "sentence2 = \"this is sentence embedding\"\n",
    "\n",
    "\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b9b0ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0443, -2.0053, -1.5915],\n",
       "        [ 1.2568,  1.4348, -1.9296],\n",
       "        [-0.5228,  0.9867, -0.4589],\n",
       "        [-0.9804,  1.3372, -0.0818],\n",
       "        [ 0.6943,  1.0501, -1.7118],\n",
       "        [ 0.5269, -0.5099,  0.5838]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_tmp = len(dc)\n",
    "emb = torch.nn.Embedding(vocab_size_tmp, 3)\n",
    "emb.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1a11240",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128 # in practice starts from 768 \n",
    "hid_dim = 256 \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first= True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x)\n",
    "        _, hidden = self.rnn(x)\n",
    "        return hidden \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, vocab_size) # Classifier head, MLP head, FFNN head \n",
    "    \n",
    "    def forward(self, x , h): # hidden state from the encoder\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x,h)\n",
    "        return self.fc(out)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "    \n",
    "    def forward(self, src, tgt_in_dec ):\n",
    "        # src ... source (english sentences)\n",
    "        # tgt_in_dec ... actual german sentences that are also input to the decoder\n",
    "        hidden_enc = self.enc(src)\n",
    "        logits = self.dec(tgt_in_dec, hidden_enc)\n",
    "        return logits\n",
    "\n",
    "device = \"mps\" # cpu or cuda \n",
    "\n",
    "model = Seq2Seq(\n",
    "    Encoder(len(src_texts_vocab)),\n",
    "    Decoder(len(tgt_texts_vocab))\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d937638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 4.3803\n",
      "ich bin ein\n",
      "epoch 2: loss 3.2316\n",
      "ich habe einen plan\n",
      "epoch 3: loss 2.6660\n",
      "ich werde mich\n",
      "epoch 4: loss 2.2611\n",
      "ich werde das machen\n",
      "epoch 5: loss 1.9438\n",
      "ich kann das erklären\n",
      "epoch 6: loss 1.6822\n",
      "ich werde das tun\n",
      "epoch 7: loss 1.4607\n",
      "ich kann das erklären\n",
      "epoch 8: loss 1.2646\n",
      "ich kann das erklären\n",
      "epoch 9: loss 1.0920\n",
      "ich werde mein bestes tun\n",
      "epoch 10: loss 0.9394\n",
      "ich werde mein bestes tun\n",
      "epoch 11: loss 0.8110\n",
      "ich kann das tun\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m loss = crit(logits.reshape(-\u001b[32m1\u001b[39m, logits.size(-\u001b[32m1\u001b[39m)), tgt_out.reshape(-\u001b[32m1\u001b[39m)) \n\u001b[32m     27\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m) \u001b[38;5;66;03m# gradient clipping \u001b[39;00m\n\u001b[32m     30\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_1/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_1/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_1/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "crit = nn.CrossEntropyLoss(ignore_index=PAD) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "epochs = 20\n",
    "\n",
    "@torch.no_grad()\n",
    "def translate(prompt, max_len=max_tgt):\n",
    "    model.eval()\n",
    "    src = torch.tensor([vectorize(prompt, src_texts_vocab, max_src)], device=device)\n",
    "    h = model.enc(src)\n",
    "    ys = torch.tensor([[BOS]], device=device)\n",
    "    out_tokens = []\n",
    "    for _ in range(max_len):\n",
    "        logits = model.dec(ys, h)\n",
    "        next_id = logits[0, -1].argmax().item()\n",
    "        if next_id in (EOS, PAD): break\n",
    "        out_tokens.append(next_id)\n",
    "        ys = torch.cat([ys, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "    return \" \".join(tgt_itos[t] for t in out_tokens)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0 \n",
    "    for src, tgt_in, tgt_out in loader:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "        logits = model(src,tgt_in)\n",
    "        loss = crit(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1)) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # gradient clipping \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"epoch {epoch+1}: loss {running_loss/len(loader):.4f}\") # \n",
    "    print(translate(\"I will do my best.\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "772c9752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('enc.embedding.weight',\n",
       "              tensor([[ 0.0069, -0.0716, -0.0309,  ..., -0.0119, -0.1059,  0.0858],\n",
       "                      [ 0.1495,  0.1305,  0.4564,  ..., -0.2707,  0.7617, -0.9606],\n",
       "                      [ 1.9574, -0.9580,  0.8112,  ...,  0.9416, -0.3763, -0.1840],\n",
       "                      ...,\n",
       "                      [-0.3965, -0.5867,  0.0605,  ..., -0.6160,  0.1138,  1.4554],\n",
       "                      [-1.5110,  0.6691,  1.4929,  ...,  0.4278,  0.8104, -0.4752],\n",
       "                      [ 0.5352,  0.2932,  0.2892,  ...,  0.6478, -0.6552,  0.4084]],\n",
       "                     device='mps:0')),\n",
       "             ('enc.rnn.weight_ih_l0',\n",
       "              tensor([[ 1.7273e-01, -1.9324e-01, -1.1670e-01,  ..., -9.5050e-02,\n",
       "                       -1.0352e-01, -1.6131e-02],\n",
       "                      [ 6.0002e-02,  1.1714e-01,  3.2160e-02,  ...,  1.5135e-02,\n",
       "                       -3.1400e-02, -1.0648e-01],\n",
       "                      [ 1.2933e-02, -1.8350e-01,  1.1375e-01,  ...,  1.7294e-01,\n",
       "                        8.9767e-02,  7.1766e-02],\n",
       "                      ...,\n",
       "                      [ 1.2941e-01,  2.6075e-02,  1.1324e-01,  ..., -5.0947e-02,\n",
       "                       -5.3241e-02,  1.2667e-01],\n",
       "                      [ 8.6089e-02, -2.6374e-02, -7.6332e-02,  ...,  7.0467e-02,\n",
       "                        2.1307e-03, -5.6327e-02],\n",
       "                      [ 8.4456e-02,  1.5860e-04, -1.5374e-01,  ...,  1.6555e-01,\n",
       "                        8.6049e-02, -4.8378e-02]], device='mps:0')),\n",
       "             ('enc.rnn.weight_hh_l0',\n",
       "              tensor([[-0.0984,  0.1033, -0.1170,  ..., -0.0049,  0.0431, -0.0028],\n",
       "                      [-0.0086, -0.0224,  0.0230,  ...,  0.0485, -0.0146,  0.0661],\n",
       "                      [-0.1980,  0.0646, -0.0590,  ...,  0.0221,  0.1038,  0.1102],\n",
       "                      ...,\n",
       "                      [ 0.0829, -0.0783, -0.0679,  ...,  0.4778, -0.0191, -0.0573],\n",
       "                      [-0.0039, -0.0215, -0.2605,  ..., -0.0957,  0.3953,  0.0997],\n",
       "                      [-0.0593,  0.0492, -0.0980,  ...,  0.1149,  0.0861,  0.2509]],\n",
       "                     device='mps:0')),\n",
       "             ('enc.rnn.bias_ih_l0',\n",
       "              tensor([ 9.5626e-02, -6.4051e-03,  4.6525e-03,  1.7772e-01,  5.1159e-02,\n",
       "                       1.0898e-01,  5.6245e-02,  8.2789e-02,  2.4975e-02,  4.4576e-02,\n",
       "                      -3.8961e-02,  6.0667e-02,  9.8366e-02, -5.4501e-03,  4.6237e-02,\n",
       "                       9.4060e-02, -7.1917e-02,  9.9654e-02, -6.5849e-02,  2.0673e-02,\n",
       "                       7.3058e-02,  7.0499e-02,  1.9532e-02,  5.3018e-03, -2.3369e-02,\n",
       "                      -4.2566e-02, -5.2341e-02,  1.4507e-01,  4.5641e-02,  1.1070e-01,\n",
       "                      -1.1965e-03,  9.3646e-02,  8.7163e-02,  3.9720e-02,  3.1422e-02,\n",
       "                       4.4873e-02,  9.2609e-02,  2.4789e-02,  1.0499e-01,  1.3683e-01,\n",
       "                       5.5628e-02, -9.4217e-03,  7.0366e-02, -5.8822e-02,  2.2440e-02,\n",
       "                       3.7951e-04, -4.4360e-02,  2.6161e-02,  7.4129e-02,  7.8052e-02,\n",
       "                       1.4145e-01,  1.0272e-01,  2.7607e-01,  1.6709e-01,  1.5281e-02,\n",
       "                       1.7814e-02,  1.4718e-01,  6.4061e-02,  1.1009e-02,  8.1512e-02,\n",
       "                       5.9087e-02, -6.4230e-02, -4.3834e-02,  8.5853e-02,  7.9826e-02,\n",
       "                      -4.8804e-02,  9.6252e-02, -6.4388e-02, -1.5729e-02,  2.7063e-02,\n",
       "                       1.1297e-01, -3.1827e-02,  1.6142e-01, -1.0008e-01,  6.6812e-02,\n",
       "                      -3.1523e-02,  7.0979e-02, -7.4633e-02,  4.4754e-02, -4.5755e-02,\n",
       "                       8.3118e-02,  1.1799e-01,  8.6971e-02,  7.7821e-02, -1.8533e-02,\n",
       "                       6.2206e-02,  4.5566e-02, -4.9895e-02,  3.7156e-02,  8.6706e-02,\n",
       "                       9.7134e-02, -4.1424e-02,  9.0116e-04,  1.4477e-02, -4.2506e-02,\n",
       "                       6.1244e-03,  4.1651e-02,  4.3595e-02,  7.3356e-02, -1.0380e-01,\n",
       "                       6.3427e-02, -9.4292e-02,  8.4405e-02, -3.6702e-02,  4.8935e-02,\n",
       "                       1.0514e-01,  7.0439e-03,  1.1273e-01,  6.5026e-02,  5.0828e-02,\n",
       "                      -2.5702e-02,  9.9321e-03,  5.2672e-02,  1.2989e-03,  5.1081e-02,\n",
       "                       1.4576e-01,  2.0296e-02,  1.2675e-02, -1.4668e-02,  6.2942e-02,\n",
       "                      -4.4135e-02,  4.6541e-02,  1.2724e-01,  5.8451e-02, -5.6050e-03,\n",
       "                       2.7358e-03,  8.3834e-02, -9.4614e-03, -2.7627e-02,  3.2027e-02,\n",
       "                       2.9239e-02,  5.8192e-02, -7.0110e-02, -1.8732e-02,  4.7481e-02,\n",
       "                      -2.2258e-02,  5.6532e-02,  1.1695e-01,  1.0524e-01,  1.2627e-01,\n",
       "                       1.7922e-02,  1.7136e-02,  3.5233e-02,  3.4602e-03, -2.1913e-02,\n",
       "                       1.4278e-03,  2.2043e-02, -7.5205e-02, -1.3757e-02,  8.2503e-02,\n",
       "                       3.6269e-02,  5.4750e-02,  3.0736e-02,  6.7250e-02,  7.3124e-02,\n",
       "                       1.0403e-01,  1.2595e-01, -3.4113e-02, -3.2701e-02,  1.5276e-02,\n",
       "                      -5.1374e-02,  5.4516e-02,  1.1444e-01,  4.3483e-02, -3.8618e-02,\n",
       "                       2.0997e-01,  1.8292e-01,  5.4642e-02,  1.7058e-01,  4.8284e-02,\n",
       "                       5.9577e-02,  1.2667e-03, -1.2315e-02,  9.5388e-02,  9.3844e-02,\n",
       "                      -3.2817e-02,  3.8513e-02,  7.3196e-02, -8.5709e-03,  5.9919e-02,\n",
       "                      -6.0118e-02,  2.1374e-02,  1.2288e-02,  8.6285e-03,  1.0151e-01,\n",
       "                       3.8064e-02, -3.1164e-03,  2.6912e-02,  6.0298e-02,  9.9374e-02,\n",
       "                       4.8405e-03,  1.2177e-01,  9.7788e-02, -1.5054e-02,  9.8712e-02,\n",
       "                       3.9501e-02, -1.1534e-02,  8.7921e-02, -6.1125e-02, -5.3104e-02,\n",
       "                       2.1693e-01,  2.4031e-02,  7.0970e-03,  3.4009e-03,  4.2150e-02,\n",
       "                       7.8569e-02,  7.9880e-02, -6.1085e-03, -6.1585e-02,  1.8024e-02,\n",
       "                      -5.7871e-02, -1.0779e-02, -6.0127e-02,  1.0373e-02,  3.6875e-02,\n",
       "                       3.5267e-02, -9.2531e-02, -9.7133e-02,  1.8266e-01, -7.8173e-02,\n",
       "                       9.7135e-02,  8.5461e-02,  1.2877e-01, -7.7637e-02,  2.5613e-02,\n",
       "                      -5.4484e-03, -2.4638e-02, -6.2158e-02,  1.1761e-02,  7.3735e-03,\n",
       "                      -2.7345e-02,  1.7430e-02,  1.6170e-01, -2.9534e-02,  2.4671e-02,\n",
       "                       5.7505e-02,  5.5167e-02,  6.4004e-02,  8.8053e-02, -5.4016e-02,\n",
       "                       1.2796e-01, -1.1744e-02, -3.2973e-02,  4.3162e-02,  6.5302e-02,\n",
       "                       4.3057e-02, -3.2328e-02,  1.1182e-02, -7.5324e-02,  2.5515e-02,\n",
       "                       2.7374e-03,  1.6442e-02,  1.1398e-01,  7.0194e-02,  1.9345e-01,\n",
       "                       7.0449e-02, -2.2574e-01, -3.8008e-02, -2.9398e-01, -1.6205e-01,\n",
       "                      -1.6862e-01, -2.6523e-01, -2.6362e-01, -8.7277e-02, -7.6210e-02,\n",
       "                      -1.5228e-01,  1.0255e-02, -6.0658e-02, -5.6920e-02, -7.3742e-02,\n",
       "                      -4.5802e-02, -1.0409e-01,  1.7109e-01, -6.4485e-02, -1.0925e-01,\n",
       "                      -1.1119e-01, -6.7813e-02, -1.4721e-01, -1.7487e-01, -7.2384e-02,\n",
       "                      -7.1791e-02, -1.7349e-01,  1.3629e-01, -1.7042e-01, -1.3069e-01,\n",
       "                      -8.9700e-02,  2.6173e-02, -2.4693e-01, -2.4395e-01, -2.0903e-01,\n",
       "                       9.6365e-02, -1.1093e-01, -1.7363e-01, -8.6164e-02,  8.5008e-02,\n",
       "                      -1.2115e-01, -9.0001e-03, -1.0714e-01, -1.2533e-01,  7.6628e-02,\n",
       "                      -7.4408e-02, -2.6379e-01, -4.3511e-02, -8.3275e-02,  1.2489e-02,\n",
       "                      -1.9311e-01, -1.6760e-01, -4.7800e-02, -4.0380e-01, -2.1551e-01,\n",
       "                      -2.5142e-01, -1.2031e-01, -2.0501e-01, -1.7547e-01, -9.6527e-02,\n",
       "                      -2.9741e-02, -2.1187e-01, -1.4117e-01, -1.0667e-01,  4.6257e-02,\n",
       "                      -1.2626e-01,  1.6382e-01, -7.6590e-02,  2.8271e-02, -7.1494e-02,\n",
       "                      -2.3505e-02, -8.9890e-03, -7.5484e-02, -2.5203e-01,  1.0958e-02,\n",
       "                      -1.2343e-01,  1.1561e-01, -1.3463e-01, -2.5282e-01, -1.4576e-01,\n",
       "                       7.1945e-02, -6.6214e-02,  2.2337e-02, -1.7800e-01,  6.8508e-02,\n",
       "                       1.3233e-01, -6.4873e-02,  4.0326e-02,  1.0585e-01, -1.4019e-01,\n",
       "                      -1.0675e-01, -1.2457e-01, -4.0200e-02,  6.9609e-02, -3.6056e-02,\n",
       "                      -1.6455e-01,  1.7708e-01, -1.6122e-01, -1.0246e-01, -6.8789e-02,\n",
       "                       1.4517e-02, -1.1643e-01,  1.9984e-03, -1.1215e-01,  7.9598e-02,\n",
       "                      -2.6836e-01, -9.5563e-02, -3.7730e-02, -1.5940e-01,  8.0698e-02,\n",
       "                      -2.5793e-01,  1.8121e-02,  2.7137e-02, -2.4544e-01,  5.8490e-02,\n",
       "                      -1.3458e-02,  5.6462e-02,  1.8436e-02, -5.6904e-02, -1.8985e-02,\n",
       "                       1.1896e-01,  5.4354e-02, -1.2177e-01, -2.6786e-01, -6.8271e-02,\n",
       "                      -1.1836e-01, -1.0449e-01, -1.7494e-02,  4.5654e-02, -1.9299e-01,\n",
       "                      -8.1695e-02, -1.5880e-01, -1.0548e-01, -1.3052e-01,  5.6573e-02,\n",
       "                      -8.4339e-02,  1.4323e-01, -8.1385e-03, -1.4939e-01,  7.9086e-02,\n",
       "                      -2.6588e-01, -2.7514e-01, -1.2766e-01, -7.2043e-02, -1.7329e-01,\n",
       "                      -1.4562e-01, -7.7671e-02, -6.0975e-02, -4.8141e-02, -3.1564e-01,\n",
       "                      -1.1875e-03, -1.5496e-02,  2.7880e-02, -5.5607e-02, -2.0391e-01,\n",
       "                      -4.6397e-02, -7.4720e-02, -3.3693e-01, -2.5491e-01, -3.3161e-01,\n",
       "                       3.1822e-02,  1.0787e-01, -7.7905e-02, -1.9924e-01, -6.3516e-03,\n",
       "                       4.3690e-02, -3.2328e-01, -4.4395e-01,  1.4897e-02, -6.8303e-02,\n",
       "                      -9.2485e-02, -2.1085e-01, -2.6400e-02,  5.8303e-03, -1.3143e-01,\n",
       "                      -1.8923e-01, -5.1310e-02,  1.0028e-04, -1.8970e-01,  7.5004e-02,\n",
       "                      -1.3964e-01,  3.7905e-02, -8.1080e-02,  2.1327e-03,  5.6632e-02,\n",
       "                      -1.1885e-01, -3.4038e-02, -5.3353e-02, -3.3919e-03, -1.4312e-01,\n",
       "                      -1.8012e-01,  3.1894e-02, -1.4014e-01, -9.2682e-02, -2.5767e-02,\n",
       "                      -6.5291e-02,  2.8960e-02,  6.0904e-02, -1.2692e-01, -2.5227e-01,\n",
       "                       2.0183e-02, -2.5246e-01, -5.9399e-02, -4.6474e-02, -1.4121e-01,\n",
       "                      -1.4695e-01, -1.7570e-01, -1.1271e-01,  9.3088e-02,  9.5730e-02,\n",
       "                      -1.8915e-01, -1.0510e-01, -1.8165e-02,  1.0573e-01,  6.1095e-02,\n",
       "                      -2.2380e-02,  6.5511e-02,  1.3072e-01,  5.7471e-02, -2.2483e-01,\n",
       "                      -2.6549e-01, -1.3466e-01, -1.3482e-01, -9.0709e-02,  1.2156e-01,\n",
       "                      -4.3829e-02, -5.4477e-02, -1.5158e-01,  1.8268e-01, -1.5867e-01,\n",
       "                      -7.0891e-04, -1.4538e-01, -3.0396e-02, -1.3296e-01,  9.8530e-02,\n",
       "                      -1.2500e-01, -2.7646e-01, -1.0077e-01, -9.4882e-02, -3.4266e-02,\n",
       "                      -1.6789e-02, -1.1391e-01,  1.0520e-01, -2.2541e-01, -2.0595e-01,\n",
       "                      -2.3656e-01, -1.2284e-01, -3.3190e-02,  4.7311e-02,  1.1488e-01,\n",
       "                      -5.4094e-03,  1.5224e-01, -2.0074e-01, -8.7065e-02, -1.4480e-01,\n",
       "                      -2.2535e-01, -1.8769e-01, -6.1887e-02,  1.1493e-02, -4.1055e-02,\n",
       "                       2.6732e-01, -7.2692e-02,  5.5587e-02,  2.0583e-01,  1.1512e-01,\n",
       "                       2.2091e-01, -1.4829e-02,  1.1345e-01, -4.4073e-02, -1.7323e-01,\n",
       "                      -2.1792e-02,  2.8295e-02, -1.1740e-01,  8.1401e-03, -1.0486e-01,\n",
       "                       1.2341e-01,  5.0520e-03,  2.1128e-01,  2.1365e-01,  5.7210e-02,\n",
       "                       9.6534e-02,  1.1504e-01, -1.0602e-01,  2.4412e-02,  2.1349e-01,\n",
       "                       1.4051e-01,  3.7603e-02, -8.3635e-02,  4.8623e-02, -1.5710e-01,\n",
       "                       1.7482e-01,  5.1622e-02,  8.0679e-02, -1.6652e-01, -1.3241e-01,\n",
       "                       6.9576e-02,  5.5306e-02, -5.8914e-03,  2.6906e-02, -3.1633e-02,\n",
       "                      -4.0250e-02, -6.1665e-02,  9.2175e-02,  3.5198e-02,  3.9049e-02,\n",
       "                       1.3708e-01,  5.2180e-02,  4.6861e-02,  1.7763e-03, -1.1594e-01,\n",
       "                      -3.8801e-02, -1.1216e-01,  6.9643e-02, -1.8672e-01, -1.0045e-01,\n",
       "                       1.8430e-02,  8.2774e-02, -1.2413e-01, -1.2688e-01,  9.0477e-02,\n",
       "                       3.9709e-02,  2.1195e-01,  7.4416e-03, -2.4310e-01,  2.9241e-02,\n",
       "                      -1.0547e-01, -5.4636e-02, -2.0079e-01,  1.3355e-01, -2.4189e-01,\n",
       "                      -7.4725e-02, -6.8844e-02, -2.6476e-03, -2.6445e-01, -1.7961e-01,\n",
       "                       1.8331e-01,  6.1301e-02,  5.3100e-02, -1.0814e-02,  5.8593e-02,\n",
       "                      -1.2181e-01,  4.4037e-03,  7.3607e-02, -1.0424e-01,  1.2758e-01,\n",
       "                      -8.2934e-02,  6.2601e-02,  1.3634e-01, -3.6682e-02,  9.3266e-02,\n",
       "                      -6.7052e-02,  1.0511e-01,  5.0094e-02, -2.2024e-01, -7.5668e-02,\n",
       "                       8.4576e-02, -2.9472e-02, -7.6132e-03, -1.8112e-02, -1.6461e-03,\n",
       "                      -1.2972e-02, -1.2012e-01,  1.4543e-01,  1.3053e-01, -1.0643e-01,\n",
       "                      -1.3134e-01,  4.6766e-02,  2.3848e-02,  1.2022e-02, -4.0939e-02,\n",
       "                      -7.8620e-02,  2.8603e-02, -8.1872e-02,  1.9041e-01,  8.0771e-02,\n",
       "                      -1.1017e-01, -1.9096e-01,  1.0877e-02, -1.6995e-01, -3.4729e-02,\n",
       "                       3.1985e-02, -7.1666e-02, -9.1831e-02,  3.3199e-05, -8.2621e-02,\n",
       "                       1.0178e-01,  3.6101e-02,  1.0439e-01, -9.0056e-02,  3.4990e-02,\n",
       "                      -8.3691e-02, -1.7578e-01, -1.2049e-02, -2.7260e-02, -1.1083e-02,\n",
       "                       1.5789e-01,  7.8822e-02, -1.2098e-01,  1.3462e-02, -9.8793e-02,\n",
       "                       3.4842e-02, -1.0582e-01,  2.5123e-02,  1.3593e-01, -1.0855e-01,\n",
       "                      -3.5843e-02,  6.3007e-02,  3.0236e-02, -1.5713e-01, -1.7073e-01,\n",
       "                      -1.2307e-01,  2.7376e-02, -1.7687e-01, -1.1899e-01,  5.0846e-02,\n",
       "                       1.2873e-01, -1.6039e-01,  1.0037e-01,  1.1564e-01,  7.4409e-02,\n",
       "                      -8.9638e-02,  2.5686e-02, -9.1585e-02, -1.7151e-01, -1.1104e-01,\n",
       "                      -2.3466e-01, -3.9376e-02, -9.3796e-02,  2.0649e-01, -1.0103e-02,\n",
       "                      -5.3588e-02,  8.4442e-02,  3.2944e-03, -3.9991e-02,  1.2208e-01,\n",
       "                      -6.0370e-02,  5.1741e-02, -7.4309e-02,  1.9840e-01, -3.7787e-02,\n",
       "                       8.9572e-02, -1.7807e-01, -1.8813e-02, -5.0157e-02,  4.1730e-02,\n",
       "                       1.4063e-01,  1.8210e-02, -6.7012e-02,  2.7380e-02,  9.5012e-02,\n",
       "                      -1.9918e-02,  1.8214e-01,  1.1245e-01, -3.3209e-02,  2.0854e-02,\n",
       "                       3.0489e-02, -1.1834e-02, -2.0465e-01, -8.0536e-02,  1.0170e-01,\n",
       "                       9.3570e-02, -4.2092e-04, -9.6953e-02,  2.5286e-02, -1.7561e-01,\n",
       "                      -7.6237e-02, -2.1614e-01,  3.3895e-02,  5.1317e-02, -3.8776e-03,\n",
       "                       3.8881e-02, -8.1152e-02,  1.0989e-01, -1.2245e-01, -4.9211e-02,\n",
       "                       8.7258e-02,  9.0761e-03,  6.6341e-02, -6.1212e-02, -4.1002e-02,\n",
       "                       8.3203e-02, -1.5617e-02, -1.6552e-01,  1.3024e-01, -6.2622e-02,\n",
       "                      -2.2996e-02, -1.7982e-02, -1.2463e-01, -5.4033e-02, -1.2044e-01,\n",
       "                       6.1057e-03, -8.0055e-02,  2.8294e-02, -1.1579e-01, -6.5306e-02,\n",
       "                       5.4592e-02,  3.9293e-02,  6.7742e-02,  6.6375e-02,  4.2043e-02,\n",
       "                       1.4252e-01,  1.3795e-01,  4.2284e-03, -1.0089e-01,  1.4225e-02,\n",
       "                       7.9813e-02, -1.4110e-01, -5.6707e-02, -3.8880e-03, -8.0728e-02,\n",
       "                       2.6758e-03,  9.6325e-02,  2.3768e-01], device='mps:0')),\n",
       "             ('enc.rnn.bias_hh_l0',\n",
       "              tensor([ 1.1415e-01,  2.9881e-02,  2.0049e-02,  8.1538e-02,  3.4632e-02,\n",
       "                       1.2069e-01,  3.7704e-02,  6.7505e-02, -1.2175e-02,  7.0189e-02,\n",
       "                       5.8452e-02,  9.1038e-02,  1.0670e-01, -3.4692e-03,  4.8776e-02,\n",
       "                      -1.6464e-03, -5.1655e-02,  1.5362e-01,  2.3872e-02,  9.2196e-02,\n",
       "                       1.0070e-01,  6.7666e-02,  4.5318e-02,  7.5660e-02,  7.0807e-03,\n",
       "                       5.1382e-02, -4.1735e-02,  1.1806e-01, -3.3934e-03,  1.3421e-01,\n",
       "                       3.7895e-02,  1.3996e-01,  1.6671e-02,  1.8472e-02, -2.7690e-02,\n",
       "                      -5.9843e-03,  8.3834e-02, -8.0006e-02, -1.5381e-03,  3.5378e-02,\n",
       "                      -1.3376e-02,  3.5159e-02,  8.3363e-02,  3.3636e-02, -1.0112e-02,\n",
       "                      -9.0280e-02, -4.4132e-02, -5.3718e-03,  4.9776e-02,  4.0654e-02,\n",
       "                       1.7377e-01,  2.1241e-01,  2.4935e-01,  1.1819e-01,  1.2032e-02,\n",
       "                       4.0028e-02,  1.8157e-01,  8.5351e-02,  2.3428e-02,  1.1134e-01,\n",
       "                       1.6048e-01, -4.4058e-02, -2.5746e-02,  9.7841e-03,  9.3615e-03,\n",
       "                      -5.0057e-02,  5.7447e-02, -4.3447e-02,  2.4612e-02,  5.9662e-03,\n",
       "                       3.7366e-02,  4.5568e-02,  1.4413e-01, -3.4358e-02,  3.9611e-02,\n",
       "                       2.2192e-02,  1.3067e-01, -7.9856e-02,  1.0262e-01, -4.5940e-02,\n",
       "                       5.8070e-02,  1.1112e-01,  1.7276e-01,  3.0000e-03,  6.9530e-02,\n",
       "                      -1.8975e-02, -3.3047e-02,  3.5790e-04,  3.9632e-03, -1.8922e-03,\n",
       "                       7.9266e-02, -3.6807e-02,  5.3181e-02,  5.8602e-02, -1.3003e-02,\n",
       "                      -8.0790e-03, -3.3298e-02,  1.1267e-01,  7.6585e-02,  1.0721e-03,\n",
       "                      -9.5464e-04, -5.4629e-02,  2.0744e-02, -7.1425e-02,  9.7912e-02,\n",
       "                       1.1222e-01, -4.2536e-02,  2.0715e-02,  5.8393e-02,  1.1210e-01,\n",
       "                       4.0574e-02, -3.7972e-02,  1.0614e-01, -9.9436e-03,  4.6260e-02,\n",
       "                       1.1305e-01,  1.0323e-01,  5.4764e-02,  9.3297e-03, -3.1793e-02,\n",
       "                      -8.3041e-02, -1.3503e-02,  1.5383e-01,  9.5700e-02,  6.6927e-02,\n",
       "                       2.8523e-02,  1.1377e-01, -2.5396e-02, -2.5805e-02, -1.1073e-02,\n",
       "                       6.3161e-02,  3.7148e-02, -7.4320e-02,  2.6592e-02,  9.8583e-03,\n",
       "                      -5.1254e-03,  1.2551e-02,  2.2806e-02,  2.2486e-02,  6.1526e-02,\n",
       "                       1.1642e-02,  4.2086e-02,  1.1490e-01, -8.2105e-02, -6.7087e-02,\n",
       "                       6.4816e-02,  1.4022e-02,  3.8789e-02, -1.5294e-02,  9.4823e-02,\n",
       "                       9.8108e-02,  3.5884e-02,  4.2489e-02,  5.2750e-02,  9.6013e-02,\n",
       "                      -1.1108e-02,  1.1669e-01, -3.6509e-02, -5.6750e-02, -2.8949e-02,\n",
       "                      -2.2198e-02, -3.3167e-02,  5.6166e-02,  2.9435e-02, -8.0242e-02,\n",
       "                       2.1910e-01,  1.1589e-01,  2.4324e-02,  1.6560e-01, -4.6387e-02,\n",
       "                       3.5992e-03,  2.6042e-02, -5.0007e-02,  1.3470e-01,  4.0391e-02,\n",
       "                      -7.3471e-02,  3.2855e-02,  1.8541e-01,  1.6991e-02,  4.1403e-02,\n",
       "                      -5.7093e-02,  4.8610e-02,  5.4762e-02, -1.8436e-03,  9.4767e-02,\n",
       "                      -4.5733e-02, -4.1521e-02, -2.1873e-02,  5.8355e-02,  3.7881e-02,\n",
       "                       2.7762e-02,  7.0695e-02,  5.9180e-02,  1.7702e-03,  9.4680e-02,\n",
       "                      -1.4154e-02, -2.3543e-02,  4.9161e-02,  1.5061e-02, -5.8451e-02,\n",
       "                       1.8047e-01, -6.4513e-02,  5.1271e-04, -1.1885e-02, -2.2005e-02,\n",
       "                      -1.9433e-02,  1.1943e-01,  2.7070e-03,  2.4093e-02,  7.3063e-03,\n",
       "                      -2.1793e-02, -1.5429e-02, -5.0464e-02, -2.2431e-02, -3.3851e-02,\n",
       "                       1.0878e-01, -8.7461e-02, -7.4900e-02,  2.0550e-01, -1.1961e-01,\n",
       "                       2.9849e-02,  6.8772e-02,  1.2519e-01, -1.9720e-02,  7.0440e-02,\n",
       "                       4.3147e-02,  6.7146e-02, -5.6732e-02, -6.2383e-02,  6.2185e-02,\n",
       "                       6.6023e-02, -1.2046e-02,  8.0583e-02, -3.4109e-02, -6.2326e-02,\n",
       "                       3.7639e-02,  8.9214e-02,  5.6410e-02,  2.3756e-02,  1.0983e-02,\n",
       "                       1.2150e-01, -2.4168e-02,  9.2403e-03,  5.2140e-02,  6.3057e-02,\n",
       "                       5.7787e-02,  1.2656e-02,  2.6507e-02,  2.3628e-02, -1.0713e-02,\n",
       "                       6.5730e-02,  5.3334e-02,  9.2667e-02,  9.8188e-02,  8.8778e-02,\n",
       "                       1.9158e-01, -2.1279e-01, -1.7531e-02, -3.3728e-01, -1.3711e-01,\n",
       "                      -1.9955e-01, -2.7484e-01, -2.7137e-01, -9.0646e-02, -1.6636e-01,\n",
       "                      -1.4928e-01,  1.2140e-02, -4.0501e-02, -7.2226e-02, -5.3460e-02,\n",
       "                      -1.2736e-02, -1.5304e-01,  1.1440e-01, -9.9150e-02, -1.2875e-01,\n",
       "                      -1.6618e-01, -4.1499e-02, -1.4905e-01, -1.8898e-01, -1.0528e-01,\n",
       "                      -5.8772e-02, -2.1514e-01,  1.2623e-01, -1.2159e-01, -1.1778e-01,\n",
       "                      -8.0342e-02, -5.8604e-02, -2.2799e-01, -1.7820e-01, -2.1153e-01,\n",
       "                       8.3225e-02, -6.0640e-02, -1.6842e-01, -8.6852e-02,  1.3584e-01,\n",
       "                      -1.0530e-01, -1.0881e-01, -1.0208e-01, -1.2856e-01,  1.5509e-02,\n",
       "                      -1.4481e-01, -2.9075e-01, -3.5947e-02, -9.3420e-02, -8.3414e-03,\n",
       "                      -2.0107e-01, -1.9114e-01, -1.4613e-01, -3.1186e-01, -2.9743e-01,\n",
       "                      -3.0024e-01, -1.3432e-01, -2.7831e-01, -1.8471e-01, -1.3879e-01,\n",
       "                      -6.0258e-02, -2.6069e-01, -6.1332e-02, -1.0109e-01, -8.4544e-04,\n",
       "                      -1.9067e-01,  5.7087e-02, -5.2040e-02,  4.3938e-02, -1.0095e-02,\n",
       "                      -2.3158e-02,  5.1782e-02, -9.0864e-02, -2.0586e-01,  7.7410e-02,\n",
       "                      -1.3884e-01,  1.6294e-01, -4.8423e-02, -2.1233e-01, -7.6053e-02,\n",
       "                       7.3551e-02, -6.3450e-02, -1.6879e-02, -1.4748e-01,  5.2273e-02,\n",
       "                       1.5024e-01, -1.1005e-01,  7.6393e-02,  7.2539e-02, -2.4376e-01,\n",
       "                      -5.0377e-03, -1.0670e-01, -1.0873e-02,  1.1079e-01, -7.9616e-02,\n",
       "                      -1.1265e-01,  1.7028e-01, -1.0695e-01, -7.5690e-02, -7.7896e-02,\n",
       "                       1.9252e-02, -1.2400e-01,  1.1518e-02, -2.5757e-02,  1.6071e-01,\n",
       "                      -2.0052e-01, -5.0613e-02, -2.4573e-02, -2.1035e-01,  9.8882e-02,\n",
       "                      -2.0341e-01,  4.1733e-02, -2.9615e-02, -2.6116e-01,  6.9187e-02,\n",
       "                      -1.4535e-02,  5.3371e-02,  6.1891e-02, -4.7431e-02, -1.6442e-02,\n",
       "                       1.2414e-01,  7.2687e-02, -4.9758e-02, -3.3659e-01, -3.0675e-02,\n",
       "                      -1.3056e-01, -8.5622e-02, -1.0165e-01,  2.2112e-02, -1.9911e-01,\n",
       "                      -2.4048e-02, -1.6115e-01, -6.9572e-02, -1.1239e-01,  2.3407e-05,\n",
       "                      -1.1880e-02,  9.6574e-02,  3.5130e-02, -1.2347e-01,  3.6901e-02,\n",
       "                      -2.3146e-01, -2.4451e-01, -5.7436e-02, -6.7173e-02, -1.5140e-01,\n",
       "                      -2.0578e-01, -2.9629e-02, -2.0642e-02,  7.3917e-03, -3.3283e-01,\n",
       "                      -6.1576e-02, -6.5836e-02,  1.0690e-01, -5.5326e-02, -8.0583e-02,\n",
       "                      -1.4627e-01, -6.3757e-02, -4.4814e-01, -2.3669e-01, -3.3286e-01,\n",
       "                      -5.6152e-02,  1.6195e-01, -7.8306e-02, -1.5097e-01, -9.3009e-02,\n",
       "                       1.7464e-02, -3.3149e-01, -3.4292e-01, -1.1127e-02, -9.1690e-02,\n",
       "                      -6.1857e-02, -2.0125e-01,  5.2895e-02, -7.0960e-02, -1.8604e-01,\n",
       "                      -2.2570e-01, -1.3027e-01, -1.4769e-02, -2.1572e-01,  5.5577e-02,\n",
       "                      -1.8659e-01,  4.8368e-02, -1.5370e-01, -9.3345e-02,  6.1725e-02,\n",
       "                      -8.8417e-02,  1.1929e-02, -1.8779e-02,  2.4370e-02, -1.6913e-01,\n",
       "                      -2.0208e-01, -1.4324e-02, -1.8331e-01, -7.7538e-02, -5.7763e-02,\n",
       "                       2.3786e-02,  5.2531e-02,  1.1982e-01, -1.0909e-01, -2.7569e-01,\n",
       "                       1.8346e-02, -2.3958e-01, -9.7147e-02, -3.8354e-02, -6.5987e-02,\n",
       "                      -1.9336e-01, -1.9464e-01, -5.9311e-02,  1.3626e-01,  1.0055e-01,\n",
       "                      -2.1716e-01, -1.0748e-01, -3.1589e-02, -1.1164e-02,  3.9225e-02,\n",
       "                       1.4489e-02,  2.9082e-03,  8.7633e-02, -4.5884e-02, -1.9611e-01,\n",
       "                      -1.9964e-01, -1.1794e-01, -1.5037e-01, -7.1091e-02,  6.1147e-02,\n",
       "                       5.4438e-02, -7.8663e-02, -1.8682e-01,  1.5960e-01, -1.5831e-01,\n",
       "                       7.8359e-03, -1.5484e-01, -2.2203e-02, -1.4867e-01,  7.3852e-02,\n",
       "                      -9.9521e-02, -1.9606e-01, -7.2052e-02, -1.7766e-01, -1.2868e-01,\n",
       "                       2.3729e-02, -1.4665e-01, -1.4303e-02, -2.2285e-01, -2.6059e-01,\n",
       "                      -3.5611e-01, -1.7024e-01, -3.1658e-02, -9.2401e-03,  1.2038e-01,\n",
       "                      -4.0064e-02,  4.4234e-02, -1.7668e-01, -1.4767e-01, -9.0969e-02,\n",
       "                      -2.2675e-01, -1.7916e-01,  3.0539e-02, -8.8565e-03, -5.2891e-02,\n",
       "                       2.1532e-01, -5.8079e-02,  1.5388e-01,  1.6626e-01,  1.5192e-01,\n",
       "                       1.5635e-01, -5.7110e-02,  1.8358e-02, -8.2684e-03, -1.1676e-01,\n",
       "                      -3.0382e-02,  4.1110e-02, -3.6124e-02,  1.8217e-02, -1.7001e-01,\n",
       "                       1.0093e-02,  6.0458e-02,  2.3495e-01,  1.8240e-01,  9.7963e-02,\n",
       "                       6.4273e-02,  1.7727e-01, -2.2539e-02, -1.6728e-02,  2.1454e-01,\n",
       "                      -1.2800e-03,  1.0878e-02, -9.6346e-02, -2.2222e-03, -8.3410e-02,\n",
       "                       1.5434e-01,  5.0859e-02,  4.2817e-02, -2.5902e-01, -3.2041e-02,\n",
       "                       1.2730e-01, -6.9511e-02,  1.6278e-01, -1.5614e-02, -4.2026e-02,\n",
       "                      -3.6271e-02, -1.6400e-01,  5.6103e-02, -3.3672e-02,  8.5111e-03,\n",
       "                       1.1829e-01,  6.0870e-03,  2.2897e-02,  4.6718e-02, -3.1874e-02,\n",
       "                      -6.0721e-02, -1.0822e-01,  6.8226e-02, -1.4950e-01,  3.4226e-02,\n",
       "                      -5.0001e-02,  3.5320e-02, -3.3697e-02, -1.2549e-01,  1.5851e-01,\n",
       "                       5.3651e-02,  4.9570e-02, -1.3580e-02, -2.0928e-01,  3.0192e-02,\n",
       "                      -9.2010e-02, -9.4132e-02, -2.1109e-01,  8.9184e-02, -2.5329e-01,\n",
       "                       1.7581e-02, -7.3742e-02,  6.3571e-03, -1.9408e-01, -1.5139e-01,\n",
       "                       1.2090e-01,  1.0331e-01,  6.7603e-02, -1.4949e-01,  9.3483e-02,\n",
       "                      -1.8809e-01, -5.9235e-02,  7.5391e-03, -1.4040e-02,  1.3037e-01,\n",
       "                      -9.5700e-02,  4.9445e-02,  8.7079e-02, -1.3339e-01,  1.7422e-01,\n",
       "                      -8.9180e-03,  4.8767e-02,  1.4566e-01, -4.2808e-02, -9.5857e-02,\n",
       "                       1.2935e-01,  7.6750e-03,  1.2282e-01,  7.7926e-02, -3.6560e-02,\n",
       "                       6.8169e-02, -1.8158e-01,  1.1924e-01,  1.4857e-01, -1.0541e-01,\n",
       "                      -1.3614e-01,  6.3127e-02, -5.7048e-02,  1.0040e-01, -3.0990e-02,\n",
       "                      -5.3091e-02, -9.7093e-03, -1.7255e-01,  2.0654e-01,  1.4842e-01,\n",
       "                      -2.2083e-02, -1.2980e-01, -3.5407e-02, -1.1094e-01, -2.7199e-02,\n",
       "                       4.0832e-02, -1.2960e-01, -8.7517e-02, -8.1435e-02, -3.8722e-02,\n",
       "                      -5.9712e-03,  2.0250e-02,  4.2863e-02, -2.4677e-02, -1.7727e-02,\n",
       "                      -2.2657e-02, -8.3562e-02,  8.2022e-02, -5.9453e-02,  7.2600e-02,\n",
       "                       1.7876e-01, -2.1827e-02, -1.6162e-01,  5.0325e-02, -1.1406e-01,\n",
       "                       1.6974e-01, -7.3616e-02, -1.1440e-02,  1.4908e-01, -5.6507e-02,\n",
       "                      -3.9699e-02,  6.5654e-02,  6.9957e-02, -1.0338e-01, -1.5349e-01,\n",
       "                      -7.4683e-02, -2.1617e-02, -1.1471e-01, -1.3384e-01, -1.5770e-03,\n",
       "                      -1.3054e-02, -1.2004e-01,  6.9156e-02,  7.6307e-02,  3.7490e-02,\n",
       "                      -5.0754e-02, -6.3738e-03, -1.1359e-01, -2.2125e-01, -5.2443e-02,\n",
       "                      -1.7069e-01, -6.4618e-02, -5.5489e-02,  1.9928e-01,  2.2038e-02,\n",
       "                       2.2072e-03,  9.2956e-02, -2.9335e-02, -1.6058e-02,  1.1802e-01,\n",
       "                      -1.1773e-01,  8.2306e-02, -1.0929e-01,  8.8017e-02, -6.3995e-02,\n",
       "                       3.7255e-02, -1.9636e-01,  4.3816e-02, -1.0184e-01,  3.7636e-02,\n",
       "                       1.0333e-01, -8.0239e-02, -1.1156e-01,  4.4197e-02, -1.2055e-01,\n",
       "                       1.0150e-01,  1.8382e-01,  2.8299e-02, -3.5639e-02, -1.4681e-02,\n",
       "                      -7.6974e-02,  1.7459e-02, -2.8068e-01,  1.1425e-02, -3.5057e-03,\n",
       "                       1.3076e-01,  6.2429e-02,  7.3088e-02,  2.4448e-02, -2.2931e-01,\n",
       "                      -1.0304e-01, -1.0265e-02, -3.2438e-02,  1.7247e-02,  6.6041e-02,\n",
       "                       2.2910e-02, -8.8493e-02,  1.0326e-01, -8.2645e-02,  2.5224e-03,\n",
       "                       1.0442e-01,  4.4565e-02,  2.1259e-02, -1.1900e-01, -1.3158e-01,\n",
       "                      -1.3908e-02, -9.4536e-02, -1.5589e-01,  6.2058e-02,  4.0038e-02,\n",
       "                       1.5466e-02, -8.7740e-02, -4.2096e-02, -6.9565e-02, -7.9056e-02,\n",
       "                      -4.2631e-02, -8.5861e-02,  1.9080e-01, -1.2477e-01, -4.4611e-02,\n",
       "                       6.2340e-02, -3.8186e-02,  6.4185e-02,  9.0532e-02, -2.5783e-04,\n",
       "                       1.1078e-01,  5.5265e-02, -4.5608e-02, -1.7636e-02,  1.7081e-01,\n",
       "                      -3.9691e-02, -9.8901e-02, -1.2906e-01,  5.9930e-02, -1.3770e-01,\n",
       "                       1.4920e-02,  3.8832e-02,  1.8729e-01], device='mps:0')),\n",
       "             ('dec.embedding.weight',\n",
       "              tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                      [ 0.7046,  0.1550,  1.5124,  ...,  1.4458,  0.0373,  0.8169],\n",
       "                      [ 0.7254,  0.2806, -0.1084,  ..., -1.6553,  0.0986,  0.6681],\n",
       "                      ...,\n",
       "                      [-0.4282,  1.0414,  0.8748,  ...,  0.3747,  0.2624,  0.0654],\n",
       "                      [ 1.4082, -0.5699,  0.2478,  ...,  1.2051, -0.0334,  0.4652],\n",
       "                      [-0.2594,  1.6268, -0.1248,  ...,  0.0780, -0.6249, -0.1260]],\n",
       "                     device='mps:0')),\n",
       "             ('dec.rnn.weight_ih_l0',\n",
       "              tensor([[ 0.0212, -0.1119,  0.0212,  ...,  0.0561,  0.1655,  0.0385],\n",
       "                      [-0.0555, -0.0695,  0.0034,  ...,  0.0316,  0.2944,  0.0742],\n",
       "                      [ 0.0196,  0.0306,  0.1401,  ..., -0.1371,  0.0563,  0.3806],\n",
       "                      ...,\n",
       "                      [-0.0281,  0.0055,  0.0358,  ...,  0.0333,  0.2512, -0.0500],\n",
       "                      [-0.0102, -0.0925,  0.1015,  ..., -0.1164, -0.1079,  0.0522],\n",
       "                      [ 0.1060,  0.1210, -0.1301,  ...,  0.0632, -0.0091, -0.0240]],\n",
       "                     device='mps:0')),\n",
       "             ('dec.rnn.weight_hh_l0',\n",
       "              tensor([[ 0.0750,  0.0040, -0.0190,  ...,  0.2042,  0.0360,  0.0235],\n",
       "                      [-0.1669,  0.0674, -0.0466,  ...,  0.0766, -0.0375,  0.0244],\n",
       "                      [ 0.0248,  0.2152,  0.0812,  ...,  0.0633, -0.0862,  0.0719],\n",
       "                      ...,\n",
       "                      [-0.0866,  0.1443, -0.0653,  ...,  0.1414, -0.0085, -0.1412],\n",
       "                      [-0.2040, -0.0994,  0.0225,  ...,  0.0832,  0.0578, -0.0723],\n",
       "                      [-0.0200,  0.0607, -0.0221,  ...,  0.1582,  0.1120,  0.1217]],\n",
       "                     device='mps:0')),\n",
       "             ('dec.rnn.bias_ih_l0',\n",
       "              tensor([ 7.6167e-02,  7.2344e-03,  5.6261e-02,  1.1846e-01,  1.6964e-01,\n",
       "                       8.8845e-02,  2.2525e-02,  7.4199e-02,  7.5101e-02,  1.0556e-01,\n",
       "                       8.0431e-02,  4.1042e-02,  7.3474e-02,  1.1722e-01,  6.0184e-02,\n",
       "                       8.6739e-02,  4.1747e-02,  2.4795e-02,  7.7061e-02,  1.0990e-01,\n",
       "                       4.4343e-02,  7.2000e-02,  1.0533e-01,  8.0276e-02,  1.0405e-01,\n",
       "                       1.0679e-01,  7.9708e-02,  6.6213e-02, -1.1132e-02,  1.5852e-01,\n",
       "                       6.6821e-02,  1.2228e-01,  9.2573e-02,  1.4892e-01,  4.5532e-02,\n",
       "                       1.3005e-01,  4.0772e-02,  6.2422e-02,  5.6928e-02,  9.5846e-03,\n",
       "                       2.0705e-02,  1.5583e-02,  1.1136e-01,  9.8717e-02,  1.0429e-01,\n",
       "                       4.7127e-02,  7.5924e-03,  6.9110e-02,  1.2963e-01,  1.5556e-01,\n",
       "                      -4.1043e-02,  1.1361e-01,  1.7308e-01,  9.4605e-02, -4.3693e-03,\n",
       "                       8.1454e-02,  1.0944e-01,  1.5470e-01,  6.3340e-02,  6.4237e-02,\n",
       "                      -1.0187e-02,  1.2149e-01,  1.5260e-01,  1.4586e-01,  9.9942e-02,\n",
       "                       3.3217e-02,  2.1693e-02,  7.0907e-02,  9.3527e-02,  8.3190e-02,\n",
       "                       1.1913e-01,  1.8342e-02,  1.0907e-01,  1.6473e-01,  1.5754e-01,\n",
       "                       1.4863e-01,  3.1001e-02,  4.1248e-02,  1.0537e-01,  2.8205e-02,\n",
       "                       9.6534e-02,  6.5098e-02,  5.9341e-02,  1.4567e-01,  1.1887e-02,\n",
       "                      -5.4773e-02,  3.2400e-02,  1.3152e-01,  3.1830e-02,  7.9313e-02,\n",
       "                       4.1362e-02,  1.5968e-01,  9.6709e-02,  1.0868e-01,  5.0877e-02,\n",
       "                       1.3516e-01,  3.5576e-02,  1.3690e-01,  8.0843e-02,  8.2074e-02,\n",
       "                       1.0040e-02,  6.7152e-02,  1.5693e-01,  4.6810e-02,  1.5392e-02,\n",
       "                       4.5000e-02,  3.7588e-02,  1.6739e-01,  1.0161e-01,  1.7604e-01,\n",
       "                       9.5139e-02,  1.0498e-01,  7.4445e-02,  7.7351e-02,  5.4361e-02,\n",
       "                       7.2127e-02, -2.7399e-02,  1.2688e-01,  8.3498e-02,  1.3167e-01,\n",
       "                       3.4885e-02,  1.0298e-01,  1.9015e-01,  9.3829e-02,  7.5459e-02,\n",
       "                       8.2039e-02,  9.8684e-02, -6.1400e-03,  1.1618e-01,  1.4455e-01,\n",
       "                       8.2994e-02,  1.5741e-01,  5.1999e-02,  7.4407e-02,  9.5122e-02,\n",
       "                       1.6880e-02,  7.8915e-02,  1.2341e-01,  5.7572e-02,  1.4544e-01,\n",
       "                       7.6300e-02,  1.3506e-01,  6.9045e-02, -4.0109e-02,  3.4218e-02,\n",
       "                       1.0871e-01,  7.5100e-02,  1.0738e-01,  7.0546e-02,  4.5502e-02,\n",
       "                       2.7413e-02,  1.0043e-01,  7.1873e-02,  1.2290e-01,  1.4579e-01,\n",
       "                       1.6677e-01,  5.7010e-02,  1.5144e-01,  5.3213e-02,  1.1550e-01,\n",
       "                       1.2717e-01, -5.4901e-03,  8.8476e-02,  1.2528e-01,  8.2077e-02,\n",
       "                       8.7267e-02,  4.2818e-02,  7.5459e-02,  1.4865e-01,  1.3614e-01,\n",
       "                      -2.8788e-02,  1.8338e-01, -4.0437e-03,  1.0582e-01,  9.7244e-02,\n",
       "                       9.3265e-02,  4.9380e-02,  1.0070e-01,  4.5609e-02,  6.2528e-02,\n",
       "                       2.7712e-02,  8.0984e-02,  1.3284e-01,  2.2814e-02,  1.6674e-01,\n",
       "                       1.2872e-01,  5.3910e-02,  8.3687e-02,  1.7121e-01,  1.2815e-01,\n",
       "                       7.7661e-02,  5.6625e-02,  5.8773e-02,  9.4406e-02,  4.5531e-02,\n",
       "                       2.0530e-02,  7.2817e-02,  2.1690e-02,  1.8712e-01,  8.1928e-02,\n",
       "                       8.9422e-02,  6.8610e-02,  1.2941e-01,  8.6806e-02,  2.2276e-02,\n",
       "                       1.0130e-01,  9.5345e-02,  1.4593e-01,  4.9231e-02,  1.2292e-03,\n",
       "                       5.4781e-03,  6.5564e-02,  1.3102e-01,  1.4308e-01,  1.1288e-01,\n",
       "                       1.3767e-01,  4.5526e-02,  5.5304e-02, -2.5250e-02,  8.1143e-02,\n",
       "                       3.2595e-02,  4.1495e-02,  1.4186e-01,  1.5839e-01,  4.4179e-02,\n",
       "                       6.7469e-02,  1.3168e-01,  1.1921e-01,  2.7949e-02,  1.6314e-02,\n",
       "                      -4.1909e-03,  1.3778e-01,  8.0176e-02,  4.7693e-02,  3.3068e-02,\n",
       "                       1.9366e-01,  5.0273e-02,  6.3882e-02,  3.7191e-02,  1.0731e-01,\n",
       "                       1.2903e-01,  1.8166e-01,  1.5302e-02,  5.4511e-02,  7.8028e-02,\n",
       "                       1.1914e-01,  1.2844e-01,  1.7590e-01,  5.3149e-02,  5.1339e-02,\n",
       "                       1.0047e-01,  9.1714e-02,  9.0903e-02,  7.6848e-02,  2.6965e-02,\n",
       "                       2.2940e-02,  6.6873e-03, -9.9490e-02, -1.9961e-01,  1.1243e-01,\n",
       "                      -4.8624e-02,  8.2795e-02, -1.7198e-01,  1.3010e-02, -2.3006e-01,\n",
       "                      -4.3184e-02, -2.5853e-01, -6.7389e-02, -3.0837e-03,  8.8195e-03,\n",
       "                      -1.3294e-01, -1.1392e-01, -2.0681e-01, -3.9861e-02, -2.1615e-01,\n",
       "                      -8.9713e-02, -1.8910e-01, -1.7163e-01, -8.4745e-02, -2.1414e-01,\n",
       "                      -1.4626e-02, -2.2103e-01, -1.0770e-01, -2.2631e-01, -1.5527e-01,\n",
       "                       7.4399e-04, -8.2894e-02, -5.0934e-02,  2.7694e-02, -1.2880e-01,\n",
       "                      -1.5997e-01, -3.1676e-02, -1.8794e-03, -1.6604e-01, -7.8752e-02,\n",
       "                      -1.3548e-01, -5.6270e-02, -2.1115e-01, -1.8387e-01, -2.6791e-01,\n",
       "                       7.9565e-02, -1.1009e-01, -2.6548e-01, -9.0007e-02,  8.8467e-02,\n",
       "                      -1.1884e-01, -1.2055e-01,  3.0744e-02,  1.2782e-01,  6.6450e-02,\n",
       "                      -2.5268e-02, -2.4461e-01,  7.2588e-02,  3.1969e-02, -7.7501e-02,\n",
       "                      -1.5131e-01, -1.3669e-01, -2.6528e-01, -1.2908e-01,  1.2975e-01,\n",
       "                       1.6291e-01, -1.7033e-01, -2.3901e-02, -5.3340e-02, -1.1270e-01,\n",
       "                      -5.4396e-02, -3.7327e-02, -1.2492e-01,  1.1785e-01, -2.5545e-01,\n",
       "                      -5.8744e-03, -1.0782e-01, -2.8107e-01, -1.3970e-01, -2.4772e-01,\n",
       "                      -2.2240e-01, -7.6415e-02,  5.6468e-04, -1.0228e-01, -7.9634e-02,\n",
       "                      -2.2216e-01, -7.9568e-02,  1.1558e-01, -4.7455e-02, -2.0827e-01,\n",
       "                       6.9548e-02, -6.9813e-02, -2.2312e-01, -1.6251e-01, -2.2827e-01,\n",
       "                      -2.1654e-01, -1.8318e-01,  8.0246e-02, -1.0075e-01,  1.0539e-01,\n",
       "                       1.4100e-02,  5.0532e-02, -2.3097e-01,  4.4064e-02, -1.1219e-01,\n",
       "                      -1.5007e-01, -1.1639e-01, -2.7380e-01, -2.8553e-01, -2.0033e-01,\n",
       "                      -5.6880e-02, -2.6538e-01, -2.0005e-01, -2.1845e-01, -2.3731e-01,\n",
       "                      -2.1147e-01, -1.8782e-01, -1.2879e-01, -2.2001e-01, -1.5371e-01,\n",
       "                      -1.2429e-01, -3.0716e-01, -1.8499e-01, -1.2122e-01, -1.3263e-02,\n",
       "                      -3.2802e-01, -6.0218e-02, -4.5934e-02, -9.9436e-02, -4.0340e-02,\n",
       "                      -1.5701e-01, -2.2547e-01, -9.7102e-02, -1.6769e-01, -3.7927e-03,\n",
       "                      -2.1588e-01, -2.0972e-01, -5.3224e-02,  9.1606e-04, -9.3275e-02,\n",
       "                      -3.8222e-02, -2.3717e-01, -2.4908e-01, -8.7764e-02, -2.3628e-01,\n",
       "                      -6.6222e-02, -2.1893e-01, -1.1060e-01, -1.4019e-01, -2.1721e-01,\n",
       "                       1.0442e-02, -4.5022e-02, -2.9746e-01, -7.3507e-02, -8.0937e-02,\n",
       "                       2.8947e-02, -4.0765e-02, -6.5702e-02, -2.5087e-02,  1.2956e-01,\n",
       "                      -2.3418e-01, -1.0186e-01, -1.7250e-01, -8.7770e-02,  1.7589e-03,\n",
       "                       3.2779e-02, -3.7580e-04, -8.4281e-02, -1.8817e-01,  1.6976e-01,\n",
       "                      -1.8624e-01, -2.0306e-01, -1.1646e-01, -1.4969e-01, -2.3211e-01,\n",
       "                       1.2258e-01, -9.4767e-02, -1.4167e-01, -5.0634e-02, -9.8772e-02,\n",
       "                      -2.8873e-01, -1.7886e-01, -2.2807e-01, -3.4589e-01, -2.3404e-01,\n",
       "                      -6.0601e-02, -1.6284e-01, -1.4169e-01, -3.1762e-01,  2.0403e-01,\n",
       "                       1.5466e-01,  3.7588e-02,  5.4593e-02, -4.1154e-02, -2.2663e-01,\n",
       "                      -7.5271e-02, -1.4902e-01, -2.0347e-01, -4.7685e-02, -1.6115e-01,\n",
       "                      -3.2926e-01,  8.8897e-02, -1.6779e-01, -8.2795e-02, -2.7260e-01,\n",
       "                      -1.1297e-01, -3.4755e-01, -3.2621e-01, -2.9751e-01, -1.9925e-01,\n",
       "                      -3.4533e-01,  9.6089e-02, -2.5337e-02, -2.2696e-01, -6.5084e-02,\n",
       "                      -4.3237e-02, -1.6196e-01, -1.2226e-01, -2.7890e-01,  1.5641e-02,\n",
       "                      -4.2176e-02,  1.2246e-02,  1.2391e-02, -1.9598e-01, -1.5672e-01,\n",
       "                      -1.0525e-01, -1.5759e-04,  9.6366e-02, -3.1062e-01,  4.7761e-02,\n",
       "                      -1.2640e-01, -1.1065e-01, -1.2109e-01, -5.2062e-02, -2.2072e-02,\n",
       "                      -1.2602e-01, -2.4396e-01, -3.1685e-02,  5.4026e-03,  6.7084e-02,\n",
       "                      -1.3126e-01, -2.3046e-02, -2.3494e-01, -7.1458e-02, -1.3336e-01,\n",
       "                      -7.9572e-02, -3.1264e-01, -1.1527e-01, -3.1030e-01, -5.4129e-02,\n",
       "                      -1.0650e-01,  2.9720e-02, -3.1157e-02, -1.5605e-02,  1.8619e-02,\n",
       "                      -2.2742e-01, -1.7358e-01,  1.8922e-01,  6.1497e-02, -3.2845e-03,\n",
       "                      -1.0740e-01, -1.0913e-01, -9.7354e-03,  1.6449e-01,  1.9363e-01,\n",
       "                      -1.1067e-01,  1.4112e-02,  4.7637e-02, -1.0420e-01, -1.0864e-03,\n",
       "                       1.3340e-02,  3.1329e-04, -1.1514e-02, -8.9385e-02, -9.4976e-02,\n",
       "                       4.8297e-02, -6.8829e-02,  2.1702e-01,  2.1525e-02, -4.4048e-02,\n",
       "                       5.0129e-02, -5.5891e-02, -5.9270e-02, -1.4602e-01, -4.8413e-02,\n",
       "                       1.8041e-01,  2.1024e-04, -4.8638e-02, -4.1027e-03, -1.2463e-01,\n",
       "                       1.1195e-01, -9.3028e-02,  7.3011e-02,  1.2649e-04,  7.6769e-02,\n",
       "                       1.3326e-01,  7.5273e-02, -5.0387e-02, -1.0719e-01, -3.7120e-02,\n",
       "                      -4.5254e-02, -1.3659e-01,  3.7764e-02,  1.7893e-01, -4.5281e-02,\n",
       "                       7.4744e-03,  2.0486e-02,  1.6968e-01,  1.1515e-01,  1.4235e-01,\n",
       "                      -9.0338e-02, -6.0666e-02,  1.4708e-01,  3.2232e-02, -4.0338e-02,\n",
       "                      -6.2024e-02, -7.6079e-02, -9.7630e-02,  4.3989e-02, -2.0332e-02,\n",
       "                       1.6568e-01, -1.8293e-02,  3.5067e-02,  3.6925e-02, -3.3216e-02,\n",
       "                       3.3789e-02, -1.0689e-01,  3.1000e-02, -1.3095e-01,  6.6533e-02,\n",
       "                      -5.2062e-02,  6.3584e-02, -8.7487e-02,  8.8390e-02,  8.0482e-02,\n",
       "                       1.9490e-01, -1.5633e-02,  2.3760e-02, -1.6061e-01, -1.1272e-02,\n",
       "                      -8.8661e-02,  3.8907e-02, -1.0611e-01, -1.2630e-01,  1.5079e-01,\n",
       "                       3.0271e-02,  1.3882e-01, -9.1935e-02,  5.8768e-02, -1.2433e-01,\n",
       "                      -3.2555e-03, -1.5315e-01,  1.9458e-01, -9.5991e-02,  8.9837e-02,\n",
       "                       7.1801e-02, -2.0315e-02,  8.8617e-02, -1.9077e-01,  6.3053e-02,\n",
       "                      -1.4473e-02,  1.8635e-02, -1.3560e-01,  1.3839e-01,  6.9856e-02,\n",
       "                       4.8246e-02, -5.7669e-02, -1.3106e-02,  4.8215e-02,  7.0206e-02,\n",
       "                      -6.1150e-02, -3.1666e-02, -1.8914e-02, -2.6963e-02,  1.4191e-02,\n",
       "                       5.8107e-02,  1.6045e-02,  1.2523e-01, -1.2492e-01,  1.4468e-02,\n",
       "                       1.3834e-02, -6.2028e-02, -1.2877e-01,  9.2296e-02, -4.9252e-03,\n",
       "                      -1.7359e-01, -1.0371e-01, -1.3689e-01,  2.2976e-02,  1.1940e-02,\n",
       "                      -8.4526e-02, -3.3364e-03,  3.6605e-02,  7.6571e-02, -4.1129e-03,\n",
       "                       2.3461e-03,  8.2274e-02,  1.4976e-01, -1.7741e-02,  1.7886e-02,\n",
       "                      -1.8282e-02, -5.1502e-02, -4.8247e-02, -5.8197e-02, -5.3322e-02,\n",
       "                       1.2167e-02, -4.2959e-02,  2.4159e-03, -3.3294e-02,  1.0946e-01,\n",
       "                      -1.0790e-01,  1.7364e-02, -1.2403e-01,  1.4689e-01, -5.6026e-02,\n",
       "                       5.5601e-02, -1.0613e-01,  1.8350e-01, -2.3991e-02,  1.6368e-01,\n",
       "                      -5.1154e-02, -5.5550e-02, -1.6036e-01,  3.8879e-02, -9.6350e-02,\n",
       "                      -6.3386e-02, -6.8149e-02,  6.3994e-02, -9.3285e-02,  7.1097e-02,\n",
       "                       1.1749e-01, -4.7100e-02, -7.1299e-02,  2.1764e-01,  6.9100e-02,\n",
       "                      -8.9595e-02, -5.2830e-02,  2.5107e-02, -1.7715e-01, -7.0285e-02,\n",
       "                      -1.3573e-01, -1.5203e-02, -1.2101e-01, -1.1615e-02,  3.7460e-03,\n",
       "                      -1.6755e-02, -3.9744e-02,  2.7785e-02,  8.2514e-03,  2.5368e-02,\n",
       "                       9.5675e-02, -6.8212e-02, -1.1427e-02,  3.2555e-02,  4.5147e-02,\n",
       "                      -7.9219e-03, -1.0208e-01, -5.5631e-02, -1.7628e-01,  2.2352e-02,\n",
       "                      -6.3090e-02,  3.6947e-02,  3.4170e-02,  2.7818e-02, -2.4769e-02,\n",
       "                      -9.8948e-02, -5.7590e-02, -3.3968e-02, -7.3119e-02,  1.8569e-03,\n",
       "                       7.3622e-03,  9.8278e-02, -4.0311e-02, -2.6162e-03, -1.5084e-02,\n",
       "                       1.4947e-01,  5.2713e-02, -2.0377e-02,  4.6758e-02, -1.6192e-01,\n",
       "                      -1.1322e-01, -1.9480e-02,  1.7333e-01,  6.8005e-02, -1.0457e-01,\n",
       "                      -8.9455e-02, -1.3621e-01, -5.3982e-02, -1.0873e-02,  9.2609e-02,\n",
       "                      -1.9459e-02,  2.4773e-02,  1.0464e-01, -1.0216e-02, -2.5192e-02,\n",
       "                       2.8933e-02, -9.0602e-02, -7.9047e-02, -5.2076e-02, -8.6087e-02,\n",
       "                      -7.8535e-02,  8.2720e-02,  1.6424e-02,  1.5655e-01,  7.8675e-02,\n",
       "                       7.7671e-02, -9.7867e-02, -1.5413e-01,  6.9681e-03, -9.9177e-02,\n",
       "                       1.5620e-02,  9.4726e-02,  9.6251e-02], device='mps:0')),\n",
       "             ('dec.rnn.bias_hh_l0',\n",
       "              tensor([ 0.1037,  0.0362,  0.0911,  0.1450,  0.0913,  0.1605,  0.0657,  0.0681,\n",
       "                       0.0914,  0.0677,  0.0065,  0.1478,  0.1441,  0.0544,  0.0478,  0.0734,\n",
       "                       0.0404,  0.0111,  0.0436,  0.0382,  0.0523,  0.0374,  0.0976,  0.0584,\n",
       "                       0.1281,  0.0751,  0.0975,  0.0867,  0.0485,  0.0588,  0.0259,  0.0650,\n",
       "                       0.1267,  0.0924,  0.0663,  0.1557,  0.0842,  0.1171,  0.0963,  0.1181,\n",
       "                       0.0462, -0.0470,  0.1115,  0.0310,  0.0649,  0.0419,  0.0731,  0.0976,\n",
       "                       0.1122,  0.1309,  0.0583,  0.1931,  0.1615,  0.0985,  0.1035,  0.0258,\n",
       "                       0.0990,  0.0799,  0.0892,  0.0747,  0.0287,  0.0441,  0.0829,  0.1274,\n",
       "                       0.1169,  0.0352, -0.0100,  0.0756,  0.0253,  0.0635,  0.1133,  0.0457,\n",
       "                       0.0590,  0.0638,  0.1362,  0.1076, -0.0182,  0.0478,  0.0223,  0.0197,\n",
       "                       0.0968, -0.0054,  0.1168,  0.1296,  0.0970, -0.0564,  0.1008,  0.0702,\n",
       "                       0.0210,  0.1108,  0.1042,  0.0916,  0.0962,  0.0767,  0.1108,  0.1452,\n",
       "                       0.0026,  0.2051,  0.0684,  0.1473,  0.0344, -0.0145,  0.1209,  0.1500,\n",
       "                       0.0997,  0.1347,  0.0226,  0.0942,  0.0740,  0.0590,  0.0388,  0.0416,\n",
       "                       0.0708, -0.0069,  0.0324,  0.0689,  0.0787,  0.0205,  0.1627,  0.1223,\n",
       "                       0.0255,  0.0686,  0.1336,  0.1545,  0.1010,  0.0947,  0.0906,  0.0901,\n",
       "                       0.0902,  0.1379,  0.1070,  0.0997,  0.0519,  0.0883,  0.0623,  0.0539,\n",
       "                       0.0480,  0.0718,  0.1445,  0.1216,  0.0296,  0.1240,  0.1021, -0.0227,\n",
       "                       0.1150,  0.0390,  0.0165,  0.1390,  0.0951,  0.0856,  0.0962,  0.0718,\n",
       "                       0.0516,  0.1657,  0.2013,  0.1623, -0.0232,  0.1874,  0.0111,  0.0433,\n",
       "                       0.0401, -0.0376,  0.1081,  0.0215,  0.0740,  0.0078,  0.0581,  0.1103,\n",
       "                       0.0577,  0.1306, -0.0439,  0.1036,  0.0634,  0.0654,  0.0897,  0.1163,\n",
       "                       0.1028,  0.0915,  0.1350,  0.1583,  0.0882,  0.0831,  0.1274,  0.0892,\n",
       "                       0.1225,  0.0344,  0.0895,  0.0286,  0.1168,  0.1421,  0.0546,  0.0810,\n",
       "                       0.1392,  0.0408,  0.0065,  0.0534,  0.0615,  0.0916,  0.1853,  0.0639,\n",
       "                       0.1624, -0.0239,  0.0947,  0.0986,  0.0570,  0.0941,  0.1104,  0.1139,\n",
       "                       0.0825,  0.0981,  0.1074,  0.1201,  0.0792,  0.1069,  0.1334,  0.1058,\n",
       "                       0.0545,  0.1207, -0.0172,  0.0103,  0.1119,  0.0145,  0.0722,  0.1017,\n",
       "                       0.1005,  0.0939,  0.0497,  0.0551,  0.0180,  0.0777,  0.0787,  0.0565,\n",
       "                       0.1536,  0.0784,  0.0999,  0.1335,  0.1098,  0.0522,  0.0622,  0.0666,\n",
       "                       0.1049,  0.1309,  0.0194,  0.0274,  0.1307,  0.0859,  0.1207,  0.1371,\n",
       "                       0.1202,  0.0302,  0.1236,  0.1666,  0.0342,  0.0667,  0.0510,  0.0926,\n",
       "                       0.0084, -0.1199, -0.1381,  0.0014, -0.0402,  0.0298, -0.1257,  0.0274,\n",
       "                      -0.1374, -0.0358, -0.1958, -0.1553,  0.0689, -0.1010, -0.1320, -0.1649,\n",
       "                      -0.2807, -0.0874, -0.1801, -0.1097, -0.1091, -0.1116, -0.1063, -0.1887,\n",
       "                       0.0168, -0.2389, -0.0928, -0.2397, -0.1247,  0.0189,  0.0258, -0.0269,\n",
       "                      -0.0153, -0.0398, -0.0669,  0.0082, -0.0901, -0.1910, -0.1421, -0.1601,\n",
       "                      -0.0730, -0.2039, -0.1414, -0.1664,  0.1428, -0.0509, -0.2641, -0.1034,\n",
       "                       0.1357, -0.1278, -0.1182,  0.0792,  0.0593,  0.0631, -0.0502, -0.3131,\n",
       "                       0.0546, -0.0261, -0.0533, -0.1319, -0.1460, -0.2280, -0.1997,  0.1608,\n",
       "                       0.1287, -0.1273, -0.0680, -0.0323, -0.0826, -0.0161,  0.0073, -0.1693,\n",
       "                       0.1431, -0.2427,  0.0468, -0.0523, -0.2145, -0.1747, -0.1462, -0.2177,\n",
       "                      -0.0590,  0.0392, -0.0244, -0.1258, -0.1656, -0.1286,  0.1579, -0.0413,\n",
       "                      -0.2628, -0.0071, -0.0622, -0.2499, -0.0938, -0.2149, -0.1461, -0.2412,\n",
       "                       0.1177, -0.0585,  0.1322,  0.0051,  0.0256, -0.2469,  0.0443, -0.0661,\n",
       "                      -0.1933, -0.1356, -0.2115, -0.2672, -0.2259, -0.0404, -0.2889, -0.1442,\n",
       "                      -0.3026, -0.2646, -0.1869, -0.1557, -0.1367, -0.2842, -0.1649, -0.1222,\n",
       "                      -0.2673, -0.1619, -0.0500, -0.0112, -0.2640, -0.1347, -0.0486, -0.1819,\n",
       "                      -0.0659, -0.1093, -0.1885, -0.0488, -0.1099, -0.0468, -0.1906, -0.1814,\n",
       "                       0.0253, -0.0855, -0.0922,  0.0208, -0.1562, -0.2396, -0.0782, -0.1319,\n",
       "                      -0.1543, -0.1913, -0.1065, -0.0397, -0.1491,  0.0575,  0.0192, -0.3290,\n",
       "                      -0.1123, -0.0832,  0.0147, -0.0289, -0.1156, -0.0535,  0.1003, -0.1637,\n",
       "                      -0.1812, -0.1444, -0.1217, -0.0888,  0.0384,  0.0095, -0.0552, -0.2677,\n",
       "                       0.1475, -0.2068, -0.2344, -0.1196, -0.1592, -0.2613,  0.1503, -0.0015,\n",
       "                      -0.1491,  0.0152, -0.1254, -0.2708, -0.1945, -0.1825, -0.2666, -0.2829,\n",
       "                      -0.0328, -0.2118, -0.0463, -0.3415,  0.1888,  0.1144,  0.0897, -0.0240,\n",
       "                      -0.0597, -0.1743, -0.0957, -0.1422, -0.2913, -0.0343, -0.1642, -0.2458,\n",
       "                       0.0416, -0.1319, -0.1389, -0.3305, -0.0332, -0.2668, -0.3299, -0.2361,\n",
       "                      -0.3123, -0.2711,  0.0636, -0.0493, -0.2238, -0.0954,  0.0056, -0.2081,\n",
       "                      -0.1148, -0.2522,  0.0644, -0.0956, -0.0221, -0.0189, -0.1879, -0.1780,\n",
       "                      -0.1149, -0.0279,  0.0270, -0.2899,  0.0440, -0.1178, -0.0862, -0.1626,\n",
       "                      -0.0662, -0.0972, -0.1511, -0.2321, -0.0912,  0.0173,  0.0321, -0.0936,\n",
       "                      -0.0313, -0.2722, -0.0916, -0.1714,  0.0057, -0.2897, -0.1326, -0.2427,\n",
       "                       0.0054, -0.0933,  0.0228, -0.0135, -0.0228,  0.0450, -0.1676, -0.2443,\n",
       "                       0.1747,  0.0759,  0.2378, -0.1799, -0.1583, -0.1223,  0.1288, -0.1886,\n",
       "                       0.0667, -0.1937, -0.1300, -0.0144,  0.2059,  0.2083,  0.0720, -0.2107,\n",
       "                       0.0061,  0.1426,  0.0529, -0.2300, -0.1471,  0.1914,  0.1366,  0.1544,\n",
       "                       0.1250, -0.1736, -0.0140,  0.1678, -0.1503, -0.0599, -0.0879,  0.1251,\n",
       "                      -0.1945,  0.0704,  0.0749,  0.2074, -0.0203, -0.2186, -0.0555,  0.0608,\n",
       "                       0.1173, -0.0343,  0.0913, -0.0091, -0.0865, -0.0704,  0.0949, -0.2733,\n",
       "                       0.1718,  0.2476, -0.0132,  0.1612,  0.1934, -0.1193, -0.1459,  0.0816,\n",
       "                       0.1416, -0.2097, -0.1522, -0.1702,  0.0751, -0.1873,  0.2828,  0.1784,\n",
       "                       0.1371, -0.2859,  0.0323, -0.0962,  0.0518, -0.1161, -0.0263, -0.0103,\n",
       "                       0.0909, -0.1950,  0.2033, -0.1817,  0.0908, -0.0880, -0.1014, -0.1870,\n",
       "                      -0.2167,  0.1729, -0.1567, -0.2092, -0.1881,  0.0847, -0.1676,  0.2286,\n",
       "                      -0.1549,  0.1152,  0.1843, -0.0892,  0.1102, -0.1079, -0.1131,  0.0225,\n",
       "                      -0.1181,  0.1594,  0.1663,  0.1511, -0.1860,  0.2043,  0.1906, -0.2510,\n",
       "                      -0.0184, -0.0087,  0.1436, -0.1177,  0.0865, -0.2005, -0.0791,  0.1103,\n",
       "                       0.0100, -0.0255,  0.0809, -0.2033,  0.1468,  0.0966,  0.0487,  0.2982,\n",
       "                      -0.0561,  0.0640, -0.2190,  0.2615,  0.1065, -0.2197,  0.2296,  0.1089,\n",
       "                      -0.0261,  0.0077,  0.1329, -0.2002,  0.1308, -0.1876,  0.1098, -0.0510,\n",
       "                       0.0740, -0.1809,  0.2022,  0.0888, -0.2311,  0.1618, -0.1561, -0.1227,\n",
       "                      -0.0923,  0.1720, -0.0831, -0.1854, -0.1260,  0.1500, -0.2219, -0.1207,\n",
       "                       0.1218, -0.1104,  0.1885, -0.1304, -0.1198, -0.1128, -0.0027, -0.0234,\n",
       "                      -0.0314,  0.0591, -0.1468,  0.1354,  0.1561,  0.1295,  0.1053,  0.1344,\n",
       "                       0.0983, -0.1646, -0.1840, -0.2204, -0.2069,  0.0406, -0.0908, -0.0835,\n",
       "                       0.0830,  0.1313,  0.0704,  0.1883, -0.0401,  0.1897,  0.2194,  0.1136,\n",
       "                       0.1773,  0.0720,  0.2332,  0.1739, -0.0293, -0.1411,  0.0972, -0.1310,\n",
       "                       0.2801, -0.0406, -0.0902,  0.1630, -0.1833, -0.0708, -0.2344,  0.2275,\n",
       "                       0.1295, -0.0817, -0.1821,  0.2051,  0.1790,  0.0487,  0.2059, -0.1282,\n",
       "                      -0.0345, -0.0918,  0.1126, -0.1063,  0.1811,  0.2074,  0.1429,  0.1643,\n",
       "                      -0.1808, -0.2081, -0.0813,  0.0194,  0.0917, -0.0594,  0.0829, -0.1473,\n",
       "                      -0.1342, -0.1365,  0.0900, -0.0604, -0.0801,  0.2157,  0.0964, -0.0907,\n",
       "                       0.2259, -0.1271,  0.1520,  0.1995, -0.0755, -0.2094,  0.1763, -0.1905,\n",
       "                      -0.2146,  0.0930, -0.1274,  0.0641,  0.1040, -0.0948, -0.2158,  0.0441,\n",
       "                      -0.1216, -0.0345, -0.0862,  0.1865, -0.0744,  0.2209,  0.0562,  0.0183],\n",
       "                     device='mps:0')),\n",
       "             ('dec.fc.weight',\n",
       "              tensor([[-0.1597, -0.0787,  0.0355,  ..., -0.1878,  0.0365,  0.0883],\n",
       "                      [-0.0798, -0.0656,  0.0672,  ..., -0.2705,  0.0190,  0.0721],\n",
       "                      [-0.0852, -0.0786,  0.0423,  ..., -0.2397,  0.0200,  0.0725],\n",
       "                      ...,\n",
       "                      [-0.1129, -0.1230, -0.0488,  ..., -0.0755,  0.0210, -0.0305],\n",
       "                      [-0.0717, -0.1140, -0.0630,  ..., -0.0141,  0.0352,  0.1240],\n",
       "                      [-0.2027, -0.1499, -0.1049,  ..., -0.0405,  0.1285, -0.0522]],\n",
       "                     device='mps:0')),\n",
       "             ('dec.fc.bias',\n",
       "              tensor([-0.1463, -0.1099, -0.1833,  ..., -0.1566, -0.0902, -0.1057],\n",
       "                     device='mps:0'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
