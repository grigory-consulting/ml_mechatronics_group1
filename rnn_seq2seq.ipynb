{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"I am a boy.\"\n",
    "target = \"Ich bin ein Junge.\"\n",
    "\n",
    "# ----------\n",
    "# Encoder[\"I am a boy.\"] -> h \n",
    "# Next Token Prediction \n",
    "# 1. step Decoder [h, <bos>] -> \"ich\"\n",
    "# 2. step Decoder [h, (<bos>, \"ich\")] -> \"bin\" \n",
    "# 3. step Decoder [h, (<bos>, \"ich\", \"bin\")] -> \"ein\"\n",
    "# 4. step Decoder [h, (<bos>, \"ich\", \"bin\", \"ein\")] -> \"Junge\"\n",
    "# 5. step Decoder [h, (<bos>, \"ich\", \"bin\", \"ein\", \"Junge\")] -> \"<eos>\"\n",
    "\n",
    "# X = (h, (<bos>, \"ich\", \"bin\", \"ein\", \"Junge\")) -> input for Decoder\n",
    "# y = ( \"ich\", \"bin\", \"ein\", \"Junge\", <eos>) -> target/labels for Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee0f081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "path = \"./deu.txt\"\n",
    "\n",
    "lines = open(path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "lines = lines[:20000]\n",
    "\n",
    "pairs = [ln.split(\"\\t\")[:2] for ln in lines] \n",
    "src_texts, tgt_texts = zip(*pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2609cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, UNK, BOS, EOS = 0, 1, 2, 3 # special tokens\n",
    "# PAD = Padding, UNK = Unknown,\n",
    "# BOS, EOS \n",
    "\n",
    "VOCAB_SIZE = 20004 \n",
    "\n",
    "def tokenize(s): return re.findall(r\"\\b\\w+\\b\", s.lower())\n",
    "def build_vocab(texts, max_tokens=VOCAB_SIZE):\n",
    "    from collections import Counter\n",
    "    freq = Counter(tok for t in texts for tok in tokenize(t))\n",
    "    itos = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"] + [w for w,_ in freq.most_common(max_tokens-4)]\n",
    "    return {w:i for i,w in enumerate(itos)}, itos\n",
    "src_texts_vocab, src_itos = build_vocab(src_texts)\n",
    "tgt_texts_vocab, tgt_itos = build_vocab(tgt_texts)\n",
    "\n",
    "\n",
    "\n",
    "def vectorize(text, stoi, max_len, add_bos_eos=False):\n",
    "    ids = [stoi.get(tok, UNK) for tok in tokenize(text)]\n",
    "    if add_bos_eos: ids = [BOS] + ids + [EOS]\n",
    "    ids = ids[:max_len]\n",
    "    if len(ids) < max_len: ids += [PAD]*(max_len-len(ids))\n",
    "    return ids\n",
    "\n",
    "#vectorize(src_texts[60], src_texts_vocab, 30)\n",
    "#src_texts[60]\n",
    "\n",
    "\n",
    "max_src, max_tgt = 30, 30 \n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src = torch.tensor([vectorize(t, src_texts_vocab, max_src) for t in src_batch])\n",
    "    tgt = torch.tensor([vectorize(t, tgt_texts_vocab, max_tgt, add_bos_eos=True) for t in tgt_batch])\n",
    "    tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "    return src, tgt_in, tgt_out\n",
    "\n",
    "dataset = list(zip(src_texts, tgt_texts))\n",
    "loader = DataLoader(dataset, batch_size= 64, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5458f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': 0, 'for': 1, 'is': 2, 'sample': 3, 'sentence': 4, 'this': 5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"this is sample sentence for embedding\"\n",
    "sentence2 = \"this is sentence embedding\"\n",
    "\n",
    "\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b9b0ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5272,  0.4394,  0.5539],\n",
       "        [ 0.1789, -1.1513, -2.5549],\n",
       "        [-0.6485, -0.6550, -0.7441],\n",
       "        [ 1.4792,  0.7552,  0.6131],\n",
       "        [ 2.0397,  0.1831, -0.6793],\n",
       "        [-0.9258, -0.2079,  1.1493]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(dc)\n",
    "emb = torch.nn.Embedding(vocab_size, 3)\n",
    "emb.weight.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
